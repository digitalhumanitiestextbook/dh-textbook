---
title: 왜 인문학도가 코딩과 데이터를 알아야 할까?
---

<!-- colab-button:start -->
<div class="colab-button">
  <a
    href="https://colab.research.google.com/github/digitalhumanitiestextbook/dh-textbook/blob/main/notebooks/part1_theory/03_critical_dh.ipynb"
    target="_blank"
    rel="noopener"
  >
    Colab에서 실행하기
  </a>
</div>
<!-- colab-button:end -->

## 왜 인문학도가 코딩과 데이터를 알아야 할까?

여러분, '코딩'이나 '데이터 분석'이라는 말을 들으면 어떤 느낌이 드시나요? 혹시 "나는 문과인데, 숫자는 보기만 해도 머리가 아파", "창의적인 인문학이랑 딱딱한 컴퓨터는 너무 다른 세상 이야기 아니야?" 혹은 "저건 전문가들이나 하는 거지, 내가 배울 수 있을까?" 하는 막연한 두려움이나 거리감을 느끼시나요? 충분히 그럴 수 있습니다. 하지만 정말 그럴까요? 오늘 이 시간에는 왜 우리 인문학도들이 이 낯선 세계에 조금이나마 발을 들여놓는 것이 의미 있는지, 그리고 생각보다 훨씬 흥미로운 여정이 될 수 있는지 이야기해보려 합니다. 특히 '입코딩'이라는 최신 트렌드를 중심으로요.

## 프로그래밍의 역사: 점점 사람에게 가까워지는 놀라운 여정

컴퓨터에게 우리가 원하는 일을 시키는 방법, 즉 '프로그래밍'은 지난 수십 년간 놀랍도록 발전해 왔습니다. 마치 아주 복잡한 기계를 다루는 기술이 점점 더 많은 사람들이 쓸 수 있는 편리한 도구로 변해온 과정과 같아요.

### **최초의 프로그래머들 (전선 연결의 시대)** 
상상해보세요. 방 전체를 차지하는 거대한 초기 컴퓨터(애니악 같은)가 있습니다. 이 컴퓨터로 계산 하나를 시키려면, 수백, 수천 개의 전선을 마치 스파게티 면처럼 뽑아서 다른 구멍에 일일이 꽂아야 했습니다. 프로그램을 바꾸려면 이 작업을 몇 시간, 혹은 며칠 동안 반복해야 했죠. 이때의 프로그래밍은 전자 회로 설계에 가까웠고, 극소수의 전문가만이 할 수 있는 일이었습니다. (*비유: 건물의 전기 배선을 직접 연결해서 불을 켜는 것*)

### **0과 1, 기계와의 직통 대화 (기계어 시대)** 
이후 컴퓨터가 직접 이해할 수 있는 유일한 언어, 0과 1의 조합(기계어)으로 명령을 내리는 방식이 등장합니다. 전선을 꽂는 것보다는 나아졌지만, 여전히 엄청나게 지루하고 어려운 작업이었습니다. 예를 들어 'A=B+C' 같은 간단한 계산을 시키려고 해도 수십 개의 0과 1 조합을 사람이 직접 입력해야 했고, 0 하나만 틀려도 컴퓨터는 완전히 다른 행동을 했습니다. (*비유: 외국인과 대화하는데, 오직 '네/아니오' 만으로 모든 의사를 전달하려는 시도*)

### **기호로 숨 쉬기 (어셈블리어 시대)** 
"이건 너무 힘들다!" 사람들이 생각했죠. 그래서 0과 1 대신, ADD(더하라), MOV(데이터를 옮겨라) 같이 조금 더 사람이 알아보기 쉬운 짧은 영어 기호를 사용하기 시작했습니다. 이것이 '어셈블리어'입니다. 기계어보다는 훨씬 나았지만, 여전히 컴퓨터의 두뇌(CPU) 종류마다 명령어가 달랐고, 컴퓨터 내부 구조를 잘 알아야만 쓸 수 있는 전문가의 언어였습니다. (지금도 아주 특별한 경우, 예를 들어 컴퓨터 하드웨어를 직접 제어하는 프로그램 등에서는 쓰이기도 합니다.) (*그림: 복잡한 한자 대신, 뜻이 통하는 간단한 그림 문자를 쓰는 것*)

### **체계적인 언어의 탄생 (C언어 등 고급 언어 시대)** 
드디어 C언어 같은 '고급 언어'가 등장하면서 프로그래밍은 대중화의 길을 걷기 시작합니다. `if (만약 조건이 맞으면) { 이걸 해라 }`, `for (몇 번 반복하면서) { 저걸 해라 }` 처럼, 우리가 생각하는 방식이나 영어 문장 구조와 훨씬 비슷해졌습니다. 컴퓨터 기종이 달라도 거의 동일한 코드를 사용할 수 있게 되었고, 훨씬 체계적으로 프로그램을 작성할 수 있게 되었죠. (많은 운영체제(OS)나 다른 프로그래밍 언어들이 이 C언어를 기반으로 만들어졌습니다.) 하지만 여전히 메모리 관리 같은 복잡한 부분을 프로그래머가 직접 신경 써야 하는 어려움은 있었습니다. (*그림: 레고 설명서를 보며, 다양한 블록을 조립해 원하는 모양을 만드는 것*)

### 쉽고 강력하게 Python 시대
그리고 마침내, 우리가 이 수업에서 주로 다룰 파이썬(Python) 같은 현대적인 언어들이 등장합니다. 파이썬은 특히 '사람이 읽기 쉬운 코드'를 중요하게 생각해서, 문법이 간결하고 직관적입니다. 마치 잘 쓰인 영어 에세이를 읽는 느낌을 주기도 하죠. 더 강력한 점은, 전 세계 수많은 개발자가 만들어 놓은 엄청나게 다양한 '라이브러리(기능 모음집)'가 있다는 것입니다. 예를 들어, 여러분이 디지털화된 『논어(論語)』 텍스트가 있다고 상상해보세요. 파이썬과 텍스트 분석 라이브러리(예: **`KoNLPy`**)를 이용하면, 공자(孔子)가 '인(仁)'이라는 단어를 몇 번 언급했고, '예(禮)'라는 단어는 몇 번 언급했는지 순식간에 세어볼 수 있습니다. 표 데이터를 다루는 **`Pandas`**, 텍스트 분석을 위한 **`NLTK`**나 **`KoNLPy`**, 관계망 분석을 위한 **`NetworkX`** 같은 라이브러리를 가져다 쓰면, 복잡한 기능을 단 몇 줄의 코드로 구현할 수 있습니다. 데이터를 다루고 분석하는 많은 분야, 특히 디지털 인문학에서 파이썬이 사랑받는 이유입니다. (*그림: 잘 갖춰진 최신 주방에서, 좋은 레시피와 온갖 조리 도구, 미리 손질된 재료를 이용해 요리하는 것*)

## 현재: "입코딩" / "바이브 코딩" - 대화로 코딩하기

그렇다면 지금 우리는 어디에 있을까요? 바로 "입코딩", 또는 "바이브 코딩(Vibe Coding)"이라고 부를 만한 새로운 단계에 진입하고 있습니다. 바로 인공지능(AI) 덕분이죠. 거대 언어 모델(LLM)들은 엄청난 양의 텍스트와 코드를 학습했습니다. 그 결과, 우리가 사람의 언어(한국어든 영어든)로 "내가 원하는 건 이런 거야. 이걸 하는 파이썬 코드를 만들어줘" 라고 구체적으로 요청하면, AI가 상당한 수준의 코드를 자동으로 생성해주는 시대가 되었습니다. 예를 들어, 다음과 같이 요청하는 식이죠.

> "셰익스피어의 *'햄릿'*에서 주인공 햄릿이 독백하는 부분만 찾아서 그 부분의 감정이 긍정적인지 부정적인지 분석하는 코드 짜줘"

프로그래밍의 역사가 기계의 언어에서 점점 사람의 언어로, 복잡한 기술 명세에서 '의도'와 '요청' 중심으로 이동해 온 것을 생각하면, 이 '입코딩'은 어쩌면 당연한 진화 과정일지도 모릅니다.

### 인문학도에게 "입코딩"이 열어주는 새로운 문

이것이 왜 우리에게 중요할까요?

* **넘기 쉬워진 문턱:** 이제 여러분은 파이썬의 모든 문법과 라이브러리 사용법을 달달 외워야만 컴퓨터의 도움을 받을 수 있는 것이 아닙니다. AI의 도움을 받아, **내가 무엇을 하고 싶은지 명확하게 설명**하는 능력만 있다면, 예전에는 상상하기 어려웠던 복잡한 작업도 시도해 볼 수 있습니다.
* **연구 본질에 집중:** 코딩 기술 습득에 드는 시간과 노력을 줄이고, 그 에너지를 여러분의 본래 연구 질문에 쏟을 수 있습니다. 예를 들어, "수백 편의 19세기 영국 소설에서 '산업혁명' 관련 키워드가 어떻게 등장하고 변화하는지 그 빈도를 추적하고 싶어" 또는 "삼국사기와 삼국유사에 나타난 특정 인물(예: 김유신)에 대한 묘사 방식을 비교 분석하고 싶어" 같은 질문을 AI에게 던지고, 필요한 분석 코드 생성을 요청할 수 있습니다.
* **연구의 확장과 심화:**
    * **규모의 확장:** 신문 기사를 예로 들어 볼까요? 특정 사건에 대한 여론 변화를 알기 위해 1960년대 신문 전체를 직접 읽는 것은 거의 불가능하죠. 하지만 디지털화된 신문 아카이브가 있다면, AI의 도움을 받아 특정 키워드나 인물의 언급 빈도 변화를 분석하여 당시 사회 분위기를 거시적으로 파악하는 연구를 시도해 볼 수 있습니다.
    * **새로운 관점 발견:** 여러분이 한국 근대 문학 작품들을 공부한다고 해봅시다. 작품 속 등장인물들이 서로 어떤 관계를 맺고 대화하는지를 데이터로 만들어 '네트워크 분석'을 해보면, 단순히 작품을 읽는 것만으로는 파악하기 어려웠던 인물 간의 중심성이나 숨겨진 커뮤니티 구조를 시각적으로 발견할 수도 있습니다.
    * **연구의 재현성:** 어떤 데이터를 어떻게 분석했는지 코드로 남기면, 다른 연구자들이 그 과정을 검토하고 재현하기 용이해져 연구의 투명성과 신뢰도를 높일 수 있습니다. 물론, 최종적인 의미 부여는 여전히 인문학적 해석의 영역입니다!
    * **디지털 자료 분석:** 웹사이트 아카이브, 디지털화된 고문서, SNS 텍스트 데이터(예: 특정 사회 이슈에 대한 트위터 반응 분석) 등 새로운 형태의 연구 자료에 접근하고 분석하여 동시대적 현상이나 과거의 디지털 기록을 연구할 수 있게 됩니다.

### 하지만, AI를 맹신할 수는 없다

여기까지 들으면 "와, 그럼 이제 코딩 공부 안 하고 AI한테 다 시키면 되겠네!" 라고 생각할 수도 있습니다. 하지만 안타깝게도, 아직은 그렇게 간단하지 않습니다. 현재의 생성형 AI는 마치 엄청나게 박식하고 일 처리가 빠르지만, 가끔 엉뚱한 거짓말을 하거나 실수를 하는 신입 비서와 같기 때문입니다.

* **AI의 '환각'을 간파하라:** AI는 학습한 데이터를 기반으로 그럴듯하게 말을 지어냅니다. 코드도 마찬가지입니다. 예를 들어, 여러분이 AI에게 "칸트(Kant)의 『판단력 비판』에 나타난 미학 이론의 핵심 주장을 요약해줘" 라고 요청했다고 해봅시다. AI는 자신감 있게 요약을 제시하겠지만, 그 내용에는 칸트가 다른 저작에서 했던 이야기나 심지어 칸트의 핵심 주장(예: 취미 판단의 주관적 보편성)을 미묘하게 왜곡하는 내용이 섞여 있을 수 있습니다. AI는 칸트를 '이해'한 것이 아니라, 학습 데이터에서 칸트와 미학에 관해 자주 함께 등장했던 단어들을 통계적으로 조합하여 그럴듯한 텍스트를 생성하기 때문입니다.
* **숨겨진 오류 찾기:** AI가 만든 코드가 당장은 실행될지라도, 논리적인 오류를 포함하고 있을 수 있습니다. 예를 들어, 『홍루몽(紅樓夢)』처럼 등장인물이 많은 소설에서 특정 인물의 등장 횟수를 세는 코드를 AI에게 짜달라고 했을 때, AI는 이름이 비슷하거나 동일한 호칭으로 불리는 다른 인물들을 구분하지 못하는 코드를 만들 수 있습니다. (예: '보옥'과 '가보옥'을 동일 인물로 처리해야 하는데 따로 센다거나). 이런 오류는 분석 결과의 신뢰도를 크게 떨어뜨립니다.
* **비효율적인 코드:** 때로는 AI가 매우 복잡하고 느리게 작동하는 코드를 제안할 수도 있습니다. 간단한 데이터 처리인데도 불구하고, 이미 만들어진 효율적인 라이브러리 기능을 사용하지 않고 복잡하게 구현하는 경우가 있죠. 데이터 양이 많아지면 이런 비효율성은 큰 문제가 됩니다. 100건의 데이터를 처리하는데 몇 시간이 걸리는 코드를 생성하면 문제가 있겠죠.
* **모호함의 함정:** 우리가 AI에게 내리는 요청(프롬프트)이 모호하면, AI는 자기 마음대로 해석해서 전혀 다른 결과물을 내놓습니다. 예를 들어, "플라톤의 『국가』를 분석해줘" 라고만 요청하면, AI는 단순히 책 내용을 요약해주거나 목차를 보여주는 데 그칠 수 있습니다. 하지만 만약 여러분이 "플라톤의 *『국가』*에서 '정의(`δικαιοσύνη`)'라는 단어가 각 권(book)별로 얼마나 자주 등장하는지 빈도를 계산하고, '영혼(`ψυχή`)'이라는 단어와 함께 등장하는 문장들을 찾아서 목록으로 보여줘" 처럼 구체적으로 요청한다면, 훨씬 유의미한 결과를 얻을 가능성이 높아집니다.

### 그래서 우리에게 필요한 '최소한의 근육'은?

바로 이 수업을 통해 배우게 될 기초적인 개념과 원리에 대한 이해입니다. 이것이 있어야 우리는 AI라는 강력한 도구를 제대로 활용하고, 그 한계를 인지하며, 오류를 수정할 수 있는 '컨트롤 타워* 역할을 할 수 있습니다.

1.  **데이터의 종류와 구조 이해:** 내가 다루려는 정보가 글자인지(**`str`**), 숫자인지(**`int`**, **`float`**), 날짜인지, 아니면 이런 것들이 모인 목록(**`list`**)이나 표(**`DataFrame`**), 혹은 관계망(**`Network`**)인지 알아야 합니다. 왜냐하면 데이터 종류와 구조에 따라 적용할 수 있는 분석 방법이나 AI에게 요청해야 할 내용이 완전히 달라지기 때문입니다. 
2.  **기본적인 컴퓨터 작업 방식 이해:** 컴퓨터가 순서대로 일을 처리하는 방식, 특정 조건(**`if`**)에 따라 다른 일을 하는 방식, 특정 작업을 반복(**`for`**)하는 방식에 대한 기본적인 이해가 있으면, AI가 생성한 코드가 대략 어떤 흐름으로 작동하는지 파악하는 데 도움이 됩니다. "아, 여기서 문헌 목록을 하나씩 보면서 특정 키워드가 있는지 검사하는구나", "여기서 긍정 단어 사전을 이용해서 감성 점수를 매기는구나" 정도의 흐름을 읽을 수 있게 되죠.
3.  **라이브러리의 존재 알기:** 파이썬에는 **`Pandas`** (표 데이터 처리), **`NLTK`**/**`KoNLPy`** (텍스트 처리), **`NetworkX`** (네트워크 분석) 같이 특정 작업을 매우 효과적으로 수행하는 도구 상자(라이브러리)가 있다는 사실을 아는 것만으로도 큰 차이를 만듭니다. 이걸 알아야 AI에게 "**`Pandas`**를 이용해서 표 데이터를 정리하고 특정 조건에 맞는 행만 뽑아줘" 와 같이 더 구체적이고 효율적인 요청을 할 수 있습니다.
4.  **오류 메시지 해독 및 디버깅 기초:** 코드가 잘못되었을 때 나타나는 (종종 암호 같은) 오류 메시지를 보고 아주 기본적인 원인이라도 파악하거나, 최소한 오류 메시지를 복사해서 AI에게 "이런 오류가 나는데 왜 그럴까? 어떻게 고쳐야 할까?" 라고 질문하여 문제를 해결하는 실마리를 얻으려면 기초 지식이 필요합니다.
5.  **텍스트를 보는 다양한 눈 (분석 방법 이해):** 마지막으로, 이러한 기초 지식 위에 인문학의 핵심 대상인 텍스트를 컴퓨터로 분석하는 다양한 방법들을 이해하는 것이 중요합니다. 단순히 단어의 빈도를 세는 것부터 시작해서, 텍스트에 숨겨진 주요 주제들을 찾아내는 것(**토픽 모델링**), 글의 긍정/부정 등의 감정을 분석하는 것(**감성 분석**), 텍스트에서 인물, 장소, 기관 등 중요한 개체를 인식하고 그들 사이의 관계를 파악하는 것(**개체명 인식 및 관계망 분석**)까지 여러 기법이 있습니다. 이러한 분석 방법들이 존재한다는 것을 개념적으로라도 알고 있어야, 내 연구 질문에 어떤 분석 방법이 적합할지 판단하고 AI에게 더 정확한 요청을 할 수 있습니다. "이 소설을 분석해줘"가 아니라, "이 소설들에서 나타나는 주요 주제들을 토픽 모델링으로 분석하는 코드 보여줘" 처럼요. 망치로 나무를 켤 수 없듯이, 문제에 맞는 분석 도구를 선택하고 AI를 안내하는 안목이 필요합니다. 즉, 데이터와 코드의 기본 원리를 이해해야 어떤 분석 방법을 선택하고 AI에게 요청할지, 그리고 그 결과를 어떻게 해석할지 결정할 수 있는 것입니다.

## AI 시대, '똑똑한 사용자'로서의 인문학도

결론적으로, 이 수업은 여러분 모두를 전문 프로그래머로 만드는 것이 목표가 아닙니다. 하지만 AI가 점점 더 많은 영역에서 활용될 미래 사회, 그리고 변화하는 연구 환경 속에서 여러분이 **자신의 인문학적 역량에 더해 데이터와 코딩이라는 새로운 도구를 자신감 있게 활용**할 수 있도록 돕는 것이 목표입니다.

'입코딩'은 분명 강력한 흐름이지만, 그것을 제대로 활용하기 위해서는 기초 체력이 필요합니다. 이 수업을 통해 그 기초 체력을 기르고, AI를 단순한 마법 상자가 아니라, 내가 통제하고 협력하며 연구를 진행할 수 있는 '똑똑한 조수'로 만들 수 있기를 바랍니다. 이것은 단순히 기술을 배우는 것을 넘어, 여러분의 인문학적 사고와 연구에 새로운 차원의 깊이와 넓이를 더해줄 것입니다. 디지털 인문학이라는 흥미로운 분야에 오신 것을 환영하며, 이 여정을 통해 여러분의 연구 지평이 더욱 넓어지기를 기대합니다!