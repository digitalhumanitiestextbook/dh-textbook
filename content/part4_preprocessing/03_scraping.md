---
title: 데이터 수집 - 공공데이터와 스크래핑
---

<!-- colab-button:start -->
<div class="colab-button">
  <a
    href="https://colab.research.google.com/github/digitalhumanitiestextbook/dh-textbook/blob/main/notebooks/part4_regex/03_regex_advanced.ipynb"
    target="_blank"
    rel="noopener"
  >
    Colab에서 실행하기
  </a>
</div>
<!-- colab-button:end -->

## 3.1 공공데이터

'**공공데이터(Public data)**'는 공공기관이 생성 또는 취득하여 관리하는 데이터로서, 국민의 편의 증진을 위해 제공되는 공적인 데이터를 말합니다.

공공 데이터는 국민의 세금으로 수집·관리되는 정보이기 때문이기에 **모두가 공유하고 활용할 수 있는 나눔재**의 성격을 지닙니다. 따라서 국가는 이러한 데이터를 공개할 의무가 있습니다. 

공공데이터는 그 활용을 통해 **높은 부가가치를 창출**할 수 있는 **고부가가치 공공재**로, 이러한 공공데이터를 기반으로 하는 **다양한 서비스가 확충**되고 있습니다. 이는 **시장의 성장**에 기여할 뿐 아니라, 공공 데이터 자체의 재이용을 촉구하기도 하는 등 선순환을 가져오고 있습니다.

공공 데이터를 서비스하는 대표적인 사이트로 '공공데이터포털'을 들 수 있습니다. 공공데이터포털은 공공기관이 보유한 다양한 데이터를 한곳에 모아 국민에게 개방하는 서비스로, 다음 [링크](https://www.data.go.kr/index.do)를 통해 접속할 수 있습니다.

그렇다면 어떻게 공공 데이터를 이용할 수 있을까요? 단순히 파일을 다운로드하는 방법도 있지만, 가장 흔히 사용하는 방법 중 하나가 바로 'API'라는 방법입니다.

## API와 인증키(Key)

### API
그럼 '**API(Application Programming Interface)**'는 대체 무엇일까요? API는 '응용 프로그램 프로그래밍 인터페이스'의 약자로, 서로 다른 두 소프트웨어 시스템이 상호 작용 및 통신할 수 있게끔 도와주는 일련의 규칙, 프로토콜의 집합입니다.

따라서 API의 본질적인 역할은 중개자이며, 비유하면 식당에서 사용자의 요청에 응해 음식이라는 서비스를 제공하게끔 하는 서버 역할을 수행합니다.

API를 이용함으로써 사용자는 데이터를 제공하는 시스템의 내부 구조를 일일이 알 필요 없이, 정해진 규격대로 요청하여 필요한 기능 및 데이터만을 가져와 사용하는 것이 가능합니다. 주문서에 원하는 음식을 써서 점원에게 가져다 주는 것에 비유할 수 있겠습니다.

이렇듯 API는 표준화된 접근을 가능하게 하며, 공공데이터포털은 API라는 표준화된 형식을 통해 데이터를 전달함으로써 사용자가 일관성 있게 데이터를 처리할 수 있도록 돕습니다.

### API 인증키
'**API 인증키(key)**'는 사용자가 해당 API를 사용할 수 있는 권한을 인증하기 위한 **비밀번호와 같은 고윳값**에 대응됩니다.

따라서 공공데이터포털 등에서 API 서비스를 이용하려는 사용자는 먼저 **API 인증키를 발급**받아야 합니다. 이는 서버 입장에서 **데이터의 무단 사용을 방지**하고, **사용량을 관리**하는 등의 목적으로 사용됩니다.

### 웹 통신의 기초
API를 활용한 데이터 통신을 이해하기 위해 다음의 기본적인 웹 통신 개념을 알아두어야 합니다.

먼저, '**HTTP(HyperText Transfer Protocol)**'는 하이퍼텍스트 전송을 위한 통신 규약(약속)입니다. 즉 HTTP는 간단히 말해, 웹에서 정보를 주고받는 규칙이라고 할 수 있습니다. 웹 사이트 주소가 `http`로 시작하는 것이 바로 이 규칙을 따르고 있다는 의미입니다.


웹 브라우저나 프로그램은 서버에게 특정 데이터나 서비스를 제공해 달라는 메시지를 보내는데, 이를 **'요청(Request)**'라고 합니다. 예를 들어 웹 브라우저 주소창에 `google.com`을 입력하는 행위 자체가 구글 서버에 구글 메인 페이지를 띄우기 위한 데이터를 요청하는 것입니다.

한편 요청을 받은 서버는 요청받은 내용(데이터)을 처리하여 요청한 사용자에게 메시지를 전달해 주는데 이를 '**응답(Response)**'이라고 합니다. 가령, 주소창에 주소를 입력했을 때 해당 웹 사이트 메인 페이지가 화면에 나타나는 것이 응답입니다. 

응답에는 처리 결과에 대한 '**상태 코드(Status Code)**'가 포함되며, 이는 API 요청이 성공했는지, 실패했다면 그 원인이 무엇인지를 코드를 통해 알려줍니다. 다음은 대표적인 HTTP 상태 코드의 예입니다.

| 분류 | 상태 코드 | 설명 |
| :---: | :---: | :--- |
| **성공** | **200** | 서버가 요청(Request)을 성공적으로 처리했습니다. |
| 클라이언트 오류 | **404** | Not Found, 서버가 요청한 자원(Resource)을 찾을 수 없습니다. |
| 서버 오류 | **500** | 서버에 오류가 발생하여 요청을 수행할 수 없습니다. |

## 공공데이터포털을 이용해 보자

앞서 살펴보았듯이, **공공데이터포털**은 공공기관이 개방하는 공공데이터를 한 곳에서 찾아볼 수 있도록 제공하는 국가 대표 플랫폼입니다. 공공데이터포털에서는 **API(Application Programming Interface)** 방식을 통해 데이터를 **무료로 제공**하고 있습니다. 

**API를 통한 데이터 제공 과정**은 다음과 같습니다.

1.  **사용자**가 **API**를 이용하여 공공데이터포털에 데이터를 **요청**합니다.
2.  **공공데이터포털**은 해당 데이터를 관리하는 **제공기관**에 **API**를 이용하여 데이터를 요청하여 **받아옵니다**.
3.  **공공데이터포털**은 받아온 데이터를 다시 **사용자에게 제공**합니다.

이때 데이터를 요청하기 위해서는, 공공데이터포털에 회원가입 후 원하는 데이터를 검색 등으로 찾아 '활용신청' 버튼을 누릅니다. '마이페이지'에 들어가면 개인 API인증키를 확인하실 수가 있습니다. 인증키는 인코딩 키와 디코딩 키가 나뉘는 경우가 있는데, 둘 중 대입했을 때 문제 없이 코드가 돌아가는 쪽을 사용하면 됩니다.

우리는 [경상남도_자주찾는 문화재](https://www.data.go.kr/tcs/dss/selectApiDataDetailView.do?publicDataPk=15062893) API를 예시로 데이터를 호출하고 처리하는 과정을 살펴보도록 하겠습니다.

### 환경 설정

먼저 API를 통한 데이터 요청 및 처리를 위해 다음과 같은 라이브러리를 호출합니다.

```
# 필요한 라이브러리 호출
import urllib.request               # URL 요청을 보내기 위한 urllib 모듈
from urllib.request import urlopen  # URL 요청 보내고 응답받기 위한 모듈

import pandas as pd            # 데이터프레임 처리용
from bs4 import BeautifulSoup  # XML 파싱(Parsing)용
```

* **`urllib.request`**, **`urllib.request.urlopen`**: URL에 요청을 보내고 응답을 받기 위한 기본 Python 모듈입니다.
* **`pandas`**: 앞서 살펴봤듯, 응답으로 받은 데이터를 데이터프레임(DataFrame) 형태로 정리하고 분석하기 위해 사용합니다.
* **`BeautifulSoup (bs4)`**: XML 또는 HTML 형식의 응답 데이터를 파싱(Parsing, 구문 분석)하고 원하는 정보만 추출하기 위해 사용하며, 스크래핑 과정에 특히 많이 이용되는 라이브러리입니다.

### API 요청을 위한 URL 구성

API 요청을 위해서는 '콜백 URL'과 'API 인증키', 그 외 가져오고자 하는 정보를 호출할 수 있는 '매개변수'가 필요합니다. 

$$\text{요청 URL} = \text{콜백 URL} + \text{?serviceKey} = \text{인증키}\& + \text{파라미터}\& + \text{파라미터} ... $$

* **콜백 URL**: 데이터를 요청할 대상 주소입니다. 
    * 공공데이터포털의 콜백 URL은 `http://apis.data.go.kr/...`으로 시작합니다.
* **인증키(Service Key)**: API를 사용할 권한을 인증하는 고유값으로, 보안에 각별히 주의해야 합니다.
* **파라미터**: 가져올 데이터의 조건을 설정합니다. 
    * 예시로 하단의 `numOfRows` (한 페이지 결과 수), `pageNo` (페이지 번호) 등을 들 수 있습니다.

이러한 정보는 공공데이터포털을 위시해 웹 API 서비스를 제공하는 사이트의 '참고문서'를 통해 확인할 수 있습니다. `경상남도_자주찾는 문화재` 데이터의 경우, `OpenAPI활용가이드_경상남도공공데이터_자주찾는문화재.docx` 파일이 이에 해당합니다.

```
# Call Back URL
콜백URL = 'http://apis.data.go.kr/6480000/gyeongnamcultural/gyeongnamculturallist'

# 요청 메시지 명세
인증키 = 'API_인증키_각자_발급_필요'  # 발급받은 인증키는 유출되지 않게 조심해야 합니다.
한_페이지_결과_수 = 100
페이지_번호 = 1

# API 요청을 위한 URL
url = f"{콜백URL}?serviceKey={인증키}&numOfRows={한_페이지_결과_수}&pageNo={페이지_번호}"

# URL을 열고 서버로부터 응답받음
응답결과 = urlopen(url)
```

### 응답 데이터 파싱 및 검색

서버로부터 받은 응답 결과(응답결과)는 보통 XML 형태로 되어 있습니다. 이 데이터를 사람이 또는 프로그램이 이해하기 쉬운 구조로 분석하는 과정이 '**파싱(Parsing)**'입니다.

* **BeautifulSoup 객체 생성**: `BeautifulSoup(응답결과, 'lxml-xml')`을 사용하여 XML을 파싱할 객체를 만듭니다.
* **특정 태그 검색**: 파싱 객체의 `find_all()` 메서드를 사용하여 원하는 데이터 블록을 포함하는 `<item>` 태그를 모두 찾습니다.

```
# 응답 데이터를 XML 형식으로 파싱하기 위한 BeautifulSoup 객체 생성
파싱객체 = BeautifulSoup(응답결과, 'lxml-xml')
items = 파싱객체.find_all('item')

items  # 확인용
```

* **데이터 추출 및 정리**: 찾은 `<item>` 목록을 반복문(for문)으로 순회하면서 `<DOJIJUNG_NO>`, `<MYONGCHING>` 등 원하는 필드(태그)의 문자열(string) 값을 추출하고 리스트에 정리합니다.

```
# 원하는 태그 값 가져와 중첩 리스트(Nested list)에 정리
# 빈 리스트 생성
데이터중첩리스트 = []

# i번째 item에서 특정 태그의 문자열(string) 값을 가져와 공백 제거(strip) 후 변수에 반복 할당
for i in range(len(items)):
    지정번호 = items[i].DOJIJUNG_NO.string.strip()
    명칭 = items[i].MYONGCHING.string.strip()
    명칭한문 = items[i].MYONGCHING_HANMUN.string.strip()
    문화재설명 = items[i].CONTENT.string.strip()
    면적 = items[i].MYONJUK.string.strip()
    소유자 = items[i].SOYOUJA_NAME.string.strip()
    관리자 = items[i].ADMIN_NAME.string.strip()
    시대구분 = items[i].SIDAE.string.strip()
    지정일 = items[i].JIJUNG_DATE.string.strip()

    데이터리스트 = [지정번호, 명칭, 명칭한문, 문화재설명, 면적, 소유자, 관리자, 시대구분, 지정일]

    # 빈 리스트에 위의 리스트를 삽입
    데이터중첩리스트.append(데이터리스트)

# 확인용
데이터중첩리스트
```

### 데이터프레임으로 변환 및 저장

추출된 중첩 리스트 형식의 데이터를 **pandas의 DataFrame**으로 변환하여 표 형태로 구조화합니다.

* **데이터프레임 생성**: `pd.DataFrame(데이터중첩리스트, columns=[컬럼명...])`을 사용합니다.
* **파일 내보내기**: 정리된 데이터프레임은 다음과 같은 형식으로 저장할 수 있습니다.
    * **TSV 파일**: `df.to_csv('파일명.tsv', sep='\t', index=False, encoding='utf-8-sig')`을 사용합니다.
    * **Excel 파일**: `df.to_excel('파일명.xlsx', index=False)`을 사용합니다.

```
df = pd.DataFrame(데이터중첩리스트, columns=['지정번호', '명칭', '명칭한문', '문화재설명', '면적', '소유자', '관리자', '시대구분', '지정일'])

# tsv로 내보내기
df.to_csv('경남_자주찾는_문화재.tsv', sep='\t', index=False, encoding='utf-8-sig')

# xlsx로 내보내기
df.to_excel('경남_자주찾는_문화재.xlsx', index=False)
```